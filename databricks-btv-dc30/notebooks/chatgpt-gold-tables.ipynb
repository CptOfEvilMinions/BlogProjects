{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f137eca-eac0-4b9d-ad5b-ca6f8060ef12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82cc1788-38bd-4d8e-b760-fadc8ede0a0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def get_databricks_http_path(DATABRICKS_HOST: str, DATABRICKS_PAT: str) -> str:\n",
    "    headers = {\"Authorization\": f\"Bearer {DATABRICKS_PAT}\"}\n",
    "    # List all SQL Warehouses\n",
    "    resp = requests.get(f\"https://{DATABRICKS_HOST}/api/2.0/sql/warehouses\", headers=headers)\n",
    "\n",
    "    __HTTP_PATH = \"\"\n",
    "    if resp.status_code == 200:\n",
    "        warehouses = resp.json().get(\"warehouses\", [])\n",
    "        for wh in warehouses:\n",
    "            __HTTP_PATH = wh[\"odbc_params\"][\"path\"]\n",
    "    else:\n",
    "        print(\"Error fetching warehouses:\", resp.text)\n",
    "\n",
    "    return __HTTP_PATH\n",
    "\n",
    "\n",
    "# ==== CONFIG ====\n",
    "CATALOG = os.getenv(\"DATABRICKS_CATALOG\", \"btv_dc30\")\n",
    "SCOPE = os.getenv(\"DATABRICKS_SCOPE\", \"btv_dc30\")\n",
    "SOURCE_SCHEMA = os.getenv(\"DATABRICKS_SOURCE_SCHEMA\", \"silver\")\n",
    "TARGET_SCHEMA = os.getenv(\"DATABRICKS_TARGET_SCHEMA\", \"gold\")\n",
    "\n",
    "\n",
    "DATABRICKS_HOST = dbutils.notebook.entry_point.getDbutils() \\\n",
    "    .notebook().getContext().apiUrl().get()\n",
    "\n",
    "\n",
    "DATABRICKS_HOST = os.getenv(\"DATABRICKS_HOST\", \"dbc-2ee3e0e1-ed8a.cloud.databricks.com\")\n",
    "DATABRICKS_TOKEN = dbutils.secrets.get(SCOPE, \"databricks-pat\")\n",
    "DATABRICKS_HTTP_PATH =  get_databricks_http_path(DATABRICKS_HOST, DATABRICKS_TOKEN) \n",
    "\n",
    "\n",
    "SQLALCHEMY_URL = f\"databricks://token:{DATABRICKS_TOKEN}@{DATABRICKS_HOST}?\" + f\"http_path={DATABRICKS_HTTP_PATH}&catalog={CATALOG}\"\n",
    "\n",
    "# OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] =  dbutils.secrets.get(SCOPE, \"openai-token\")\n",
    "\n",
    "# CIM docs path\n",
    "VECTOR_DOCS_DIR = os.getenv(\"VECTOR_DOCS_DIR\", \"./vector_docs\")\n",
    "CIM_DOCS_DIR = os.getenv(\"CIM_DOCS_DIR\", f\"./{VECTOR_DOCS_DIR}/splunk_cim\")\n",
    "ZEEK_DOCS_DIR = os.getenv(\"ZEEK_DOCS_DIR\", f\"./{VECTOR_DOCS_DIR}/zeek\")\n",
    "SYSMON_DOCS_DIR = os.getenv(\"SYSMON_DOCS_DIR\", f\"./{VECTOR_DOCS_DIR}/sysmon\")\n",
    "OSQUERY_DOCS_DIR = os.getenv(\"OSQUERY_DOCS_DIR\", f\"./{VECTOR_DOCS_DIR}/osquery\")\n",
    "CHROMA_DIR = os.getenv(\"CHROMA_DIR\", f\"./chroma_{CATALOG}_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef4ffd67-8a7d-4fa1-8632-0461aeadce14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Install dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ada9892e-7067-48e6-b7e4-4bfb9106e651",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -q databricks-sql-connector==4.0.5 \\\n",
    "    sqlalchemy==2.0.22 \\\n",
    "    databricks-sqlalchemy==2.0.7 \\\n",
    "    llama-index-llms-openai==0.5.4 \\\n",
    "    llama-index-embeddings-openai==0.5.0 \\\n",
    "    chromadb==1.0.20 \\\n",
    "    requests \\\n",
    "    llama-index==0.13.2 \\\n",
    "    llama-index-vector-stores-chroma==0.5.0 \\\n",
    "    beautifulsoup4==4.13.4 \\\n",
    "    tiktoken==0.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dda746b-7009-47ae-b1dc-bb59ff1fa682",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afa274f3-eb23-4553-bb45-3e9f6b58ab20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "\n",
    "\n",
    "# ==== LlamaIndex / Vector DB ====\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    Document,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.callbacks import CallbackManager, TokenCountingHandler\n",
    "import chromadb\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1eae5fb7-fd5b-4d1f-babb-3ec5fa33f9b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Init LLM and embedding models\n",
    "\n",
    "The code snippet configures a text processing environment using OpenAI models. It sets up an embedding model `text-embedding-3-large` through OpenAIEmbedding for generating vector representations of text, and a language model `gpt-4o` via OpenAI with deterministic output `temperature=0`. \n",
    "\n",
    "Both models use the API key stored in the environment variable `OPENAI_API_KEY`. Additionally, a SentenceSplitter named `NODE_PARSER` is initialized to split text into chunks of `1024` characters with an overlap of `100` characters, enabling manageable and context-aware processing for downstream tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fb09724-7307-4f25-a3c0-0855281569da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    ")\n",
    "Settings.llm = OpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "NODE_PARSER = SentenceSplitter(chunk_size=1024, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "96d16755-5dc6-46d6-bb25-172df982e4dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==== CIM MODELS ====\n",
    "CIM_DATA_MODELS = [\n",
    "    \"Alerts\",\n",
    "     \"Authentication\",\n",
    "     \"Certificates\",\n",
    "     \"Change\",\n",
    "     \"Data Access\",\n",
    "     \"Data Loss Prevention\",\n",
    "     \"Databases\",\n",
    "     \"Email\",\n",
    "     \"Endpoint\",\n",
    "     \"Event Signatures\",\n",
    "     \"Interprocess Messaging\",\n",
    "     \"Intrusion Detection\",\n",
    "     \"Inventory\",\n",
    "     \"Java Virtual Machines (JVM)\",\n",
    "     \"Malware\",\n",
    "     \"Network Resolution (DNS)\",\n",
    "     \"Network Sessions\",\n",
    "     \"Network Traffic\",\n",
    "     \"Performance\",\n",
    "     \"Splunk Audit Logs\",\n",
    "     \"TicketManagement\",\n",
    "     \"Updates\",\n",
    "     \"Vulnerabilities\",\n",
    "     \"Web\"\n",
    "]\n",
    "\n",
    "\n",
    "MODEL_HINTS = {\n",
    "    \"Alerts\": {\n",
    "        \"app\",\n",
    "        \"description\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"dest_type\",\n",
    "        \"id\",\n",
    "        \"mitre_technique_id\",\n",
    "        \"severity\",\n",
    "        \"severity_id\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_priority\",\n",
    "        \"src_type\",\n",
    "        \"tag\",\n",
    "        \"type\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_name\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_account\",\n",
    "        \"vendor_product_id\",\n",
    "        \"vendor_region\"\n",
    "    },\n",
    "    \"Authentication\": {\n",
    "        \"action\",\n",
    "        \"app\",\n",
    "        \"authentication_method\",\n",
    "        \"authentication_service\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_nt_domain\",\n",
    "        \"dest_priority\",\n",
    "        \"duration\",\n",
    "        \"reason\",\n",
    "        \"response_time\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_nt_domain\",\n",
    "        \"src_priority\",\n",
    "        \"src_user\",\n",
    "        \"src_user_bunit\",\n",
    "        \"src_user_category\",\n",
    "        \"src_user_id\",\n",
    "        \"src_user_priority\",\n",
    "        \"src_user_role\",\n",
    "        \"src_user_type\",\n",
    "        \"tag\",\n",
    "        \"user\",\n",
    "        \"user_agent\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_id\",\n",
    "        \"user_priority\",\n",
    "        \"user_role\",\n",
    "        \"user_type\",\n",
    "        \"vendor_account\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Certificates\": {\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_port\",\n",
    "        \"dest_priority\",\n",
    "        \"duration\",\n",
    "        \"response_time\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_port\",\n",
    "        \"src_priority\",\n",
    "        \"ssl_end_time\",\n",
    "        \"ssl_engine\",\n",
    "        \"ssl_hash\",\n",
    "        \"ssl_is_valid\",\n",
    "        \"ssl_issuer\",\n",
    "        \"ssl_issuer_common_name\",\n",
    "        \"ssl_issuer_email\",\n",
    "        \"ssl_issuer_email_domain\",\n",
    "        \"ssl_issuer_locality\",\n",
    "        \"ssl_issuer_organization\",\n",
    "        \"ssl_issuer_state\",\n",
    "        \"ssl_issuer_street\",\n",
    "        \"ssl_issuer_unit\",\n",
    "        \"ssl_name\",\n",
    "        \"ssl_policies\",\n",
    "        \"ssl_publickey\",\n",
    "        \"ssl_publickey_algorithm\",\n",
    "        \"ssl_serial\",\n",
    "        \"ssl_session_id\",\n",
    "        \"ssl_signature_algorithm\",\n",
    "        \"ssl_start_time\",\n",
    "        \"ssl_subject\",\n",
    "        \"ssl_subject_common_name\",\n",
    "        \"ssl_subject_email\",\n",
    "        \"ssl_subject_email_domain\",\n",
    "        \"ssl_subject_locality\",\n",
    "        \"ssl_subject_organization\",\n",
    "        \"ssl_subject_state\",\n",
    "        \"ssl_subject_street\",\n",
    "        \"ssl_subject_unit\",\n",
    "        \"ssl_validity_window\",\n",
    "        \"ssl_version\",\n",
    "        \"tag\",\n",
    "        \"transport\"\n",
    "    },\n",
    "    \"Change\": {\n",
    "        \"action\",\n",
    "        \"change_type\",\n",
    "        \"command\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_ip_range\",\n",
    "        \"dest_nt_domain\",\n",
    "        \"dest_port_range\",\n",
    "        \"dest_priority\",\n",
    "        \"direction\",\n",
    "        \"dvc\",\n",
    "        \"image_id\",\n",
    "        \"instance_type\",\n",
    "        \"object\",\n",
    "        \"object_attrs\",\n",
    "        \"object_category\",\n",
    "        \"object_id\",\n",
    "        \"object_path\",\n",
    "        \"protocol\",\n",
    "        \"result\",\n",
    "        \"result_id\",\n",
    "        \"rule_action\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_ip_range\",\n",
    "        \"src_nt_domain\",\n",
    "        \"src_port_range\",\n",
    "        \"src_priority\",\n",
    "        \"src_user\",\n",
    "        \"src_user_bunit\",\n",
    "        \"src_user_category\",\n",
    "        \"src_user_name\",\n",
    "        \"src_user_priority\",\n",
    "        \"src_user_type\",\n",
    "        \"status\",\n",
    "        \"tag\",\n",
    "        \"user\",\n",
    "        \"user_agent\",\n",
    "        \"user_name\",\n",
    "        \"user_type\",\n",
    "        \"vendor_account\",\n",
    "        \"vendor_product\",\n",
    "        \"vendor_product_id\",\n",
    "        \"vendor_region\"\n",
    "    },\n",
    "    \"Data Access\": {\n",
    "        \"action\",\n",
    "        \"app\",\n",
    "        \"app_id\",\n",
    "        \"dest\",\n",
    "        \"dest_name\",\n",
    "        \"dest_url\",\n",
    "        \"dvc\",\n",
    "        \"email\",\n",
    "        \"object\",\n",
    "        \"object_category\",\n",
    "        \"object_id\",\n",
    "        \"object_path\",\n",
    "        \"object_size\",\n",
    "        \"owner\",\n",
    "        \"owner_email\",\n",
    "        \"owner_id\",\n",
    "        \"parent_object\",\n",
    "        \"parent_object_category\",\n",
    "        \"parent_object_id\",\n",
    "        \"src\",\n",
    "        \"user\",\n",
    "        \"user_agent\",\n",
    "        \"user_group\",\n",
    "        \"user_role\",\n",
    "        \"vendor_account\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Data Loss Prevention\": {\n",
    "        \"action\",\n",
    "        \"app\",\n",
    "        \"category\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"dest_zone\",\n",
    "        \"dlp_type\",\n",
    "        \"dvc\",\n",
    "        \"dvc_bunit\",\n",
    "        \"dvc_category\",\n",
    "        \"dvc_priority\",\n",
    "        \"dvc_zone\",\n",
    "        \"object\",\n",
    "        \"object_category\",\n",
    "        \"object_path\",\n",
    "        \"severity\",\n",
    "        \"severity_id\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_priority\",\n",
    "        \"src_user\",\n",
    "        \"src_user_bunit\",\n",
    "        \"src_user_category\",\n",
    "        \"src_user_priority\",\n",
    "        \"src_zone\",\n",
    "        \"tag\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Databases\": {\n",
    "        \"availability\",\n",
    "        \"avg_executions\",\n",
    "        \"buffer_cache_hit_ratio\",\n",
    "        \"commits\",\n",
    "        \"cpu_used\",\n",
    "        \"cursor\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"dump_area_used\",\n",
    "        \"duration\",\n",
    "        \"elapsed_time\",\n",
    "        \"free_bytes\",\n",
    "        \"indexes_hit\",\n",
    "        \"instance_name\",\n",
    "        \"instance_reads\",\n",
    "        \"instance_version\",\n",
    "        \"instance_writes\",\n",
    "        \"last_call_minute\",\n",
    "        \"lock_mode\",\n",
    "        \"lock_session_id\",\n",
    "        \"logical_reads\",\n",
    "        \"logon_time\",\n",
    "        \"machine\",\n",
    "        \"memory_sorts\",\n",
    "        \"number_of_users\",\n",
    "        \"obj_name\",\n",
    "        \"object\",\n",
    "        \"os_pid\",\n",
    "        \"physical_reads\",\n",
    "        \"process_limit\",\n",
    "        \"processes\",\n",
    "        \"query\",\n",
    "        \"query_id\",\n",
    "        \"query_plan_hit\",\n",
    "        \"query_time\",\n",
    "        \"records_affected\",\n",
    "        \"response_time\",\n",
    "        \"seconds_in_wait\",\n",
    "        \"serial_num\",\n",
    "        \"session_id\",\n",
    "        \"session_limit\",\n",
    "        \"session_status\",\n",
    "        \"sessions\",\n",
    "        \"sga_buffer_cache_size\",\n",
    "        \"sga_buffer_hit_limit\",\n",
    "        \"sga_data_dict_hit_ratio\",\n",
    "        \"sga_fixed_area_size\",\n",
    "        \"sga_free_memory\",\n",
    "        \"sga_library_cache_size\",\n",
    "        \"sga_redo_log_buffer_size\",\n",
    "        \"sga_shared_pool_size\",\n",
    "        \"sga_sql_area_size\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_priority\",\n",
    "        \"start_time\",\n",
    "        \"stored_procedures_called\",\n",
    "        \"table_scans\",\n",
    "        \"tables_hit\",\n",
    "        \"tablespace_name\",\n",
    "        \"tablespace_reads\",\n",
    "        \"tablespace_status\",\n",
    "        \"tablespace_used\",\n",
    "        \"tablespace_writes\",\n",
    "        \"tag\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\",\n",
    "        \"wait_state\",\n",
    "        \"wait_time\"\n",
    "    },\n",
    "    \"Email\": {\n",
    "        \"action\",\n",
    "        \"delay\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"duration\",\n",
    "        \"file_hash\",\n",
    "        \"file_name\",\n",
    "        \"file_size\",\n",
    "        \"filter_action\",\n",
    "        \"filter_score\",\n",
    "        \"internal_message_id\",\n",
    "        \"message_id\",\n",
    "        \"message_info\",\n",
    "        \"orig_dest\",\n",
    "        \"orig_recipient\",\n",
    "        \"orig_src\",\n",
    "        \"process\",\n",
    "        \"process_id\",\n",
    "        \"protocol\",\n",
    "        \"recipient\",\n",
    "        \"recipient_count\",\n",
    "        \"recipient_domain\",\n",
    "        \"recipient_status\",\n",
    "        \"response_time\",\n",
    "        \"retries\",\n",
    "        \"return_addr\",\n",
    "        \"signature\",\n",
    "        \"signature_extra\",\n",
    "        \"signature_id\",\n",
    "        \"size\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_priority\",\n",
    "        \"src_user\",\n",
    "        \"src_user_bunit\",\n",
    "        \"src_user_category\",\n",
    "        \"src_user_domain\",\n",
    "        \"src_user_priority\",\n",
    "        \"status_code\",\n",
    "        \"subject\",\n",
    "        \"tag\",\n",
    "        \"url\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\",\n",
    "        \"xdelay\",\n",
    "        \"xref\"\n",
    "    },\n",
    "    \"Endpoint\": {\n",
    "        \"action\",\n",
    "        \"cpu_load_percent\",\n",
    "        \"creation_time\",\n",
    "        \"description\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_is_expected\",\n",
    "        \"dest_port\",\n",
    "        \"dest_priority\",\n",
    "        \"dest_requires_av\",\n",
    "        \"dest_should_timesync\",\n",
    "        \"dest_should_update\",\n",
    "        \"file_access_time\",\n",
    "        \"file_acl\",\n",
    "        \"file_create_time\",\n",
    "        \"file_hash\",\n",
    "        \"file_modify_time\",\n",
    "        \"file_name\",\n",
    "        \"file_path\",\n",
    "        \"file_size\",\n",
    "        \"mem_used\",\n",
    "        \"original_file_name\",\n",
    "        \"os\",\n",
    "        \"parent_process\",\n",
    "        \"parent_process_exec\",\n",
    "        \"parent_process_guid\",\n",
    "        \"parent_process_id\",\n",
    "        \"parent_process_name\",\n",
    "        \"parent_process_path\",\n",
    "        \"process\",\n",
    "        \"process_current_directory\",\n",
    "        \"process_exec\",\n",
    "        \"process_guid\",\n",
    "        \"process_hash\",\n",
    "        \"process_id\",\n",
    "        \"process_integrity_level\",\n",
    "        \"process_name\",\n",
    "        \"process_path\",\n",
    "        \"registry_hive\",\n",
    "        \"registry_key_name\",\n",
    "        \"registry_path\",\n",
    "        \"registry_value_data\",\n",
    "        \"registry_value_name\",\n",
    "        \"registry_value_text\",\n",
    "        \"registry_value_type\",\n",
    "        \"service\",\n",
    "        \"service_dll\",\n",
    "        \"service_dll_hash\",\n",
    "        \"service_dll_path\",\n",
    "        \"service_dll_signature_exists\",\n",
    "        \"service_dll_signature_verified\",\n",
    "        \"service_exec\",\n",
    "        \"service_hash\",\n",
    "        \"service_id\",\n",
    "        \"service_name\",\n",
    "        \"service_path\",\n",
    "        \"service_signature_exists\",\n",
    "        \"service_signature_verified\",\n",
    "        \"src\",\n",
    "        \"src_category\",\n",
    "        \"src_port\",\n",
    "        \"src_priority\",\n",
    "        \"src_requires_av\",\n",
    "        \"src_should_timesync\",\n",
    "        \"src_should_update\",\n",
    "        \"start_mode\",\n",
    "        \"state\",\n",
    "        \"status\",\n",
    "        \"tag\",\n",
    "        \"transport\",\n",
    "        \"transport_dest_port\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_id\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Event Signatures\": {\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"tag\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Interprocess Messaging\": {\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"duration\",\n",
    "        \"endpoint\",\n",
    "        \"endpoint_version\",\n",
    "        \"message\",\n",
    "        \"message_consumed_time\",\n",
    "        \"message_correlation_id\",\n",
    "        \"message_delivered_time\",\n",
    "        \"message_delivery_mode\",\n",
    "        \"message_expiration_time\",\n",
    "        \"message_id\",\n",
    "        \"message_priority\",\n",
    "        \"message_properties\",\n",
    "        \"message_received_time\",\n",
    "        \"message_redelivered\",\n",
    "        \"message_reply_dest\",\n",
    "        \"message_type\",\n",
    "        \"parameters\",\n",
    "        \"payload\",\n",
    "        \"payload_type\",\n",
    "        \"request_payload\",\n",
    "        \"request_payload_type\",\n",
    "        \"request_sent_time\",\n",
    "        \"response_code\",\n",
    "        \"response_payload_type\",\n",
    "        \"response_received_time\",\n",
    "        \"response_time\",\n",
    "        \"return_message\",\n",
    "        \"rpc_protocol\",\n",
    "        \"status\",\n",
    "        \"tag\"\n",
    "    },\n",
    "    \"Intrusion Detection\": {\n",
    "        \"action\",\n",
    "        \"category\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_port\",\n",
    "        \"dest_priority\",\n",
    "        \"dvc\",\n",
    "        \"dvc_bunit\",\n",
    "        \"dvc_category\",\n",
    "        \"dvc_priority\",\n",
    "        \"file_hash\",\n",
    "        \"file_name\",\n",
    "        \"file_path\",\n",
    "        \"ids_type\",\n",
    "        \"severity\",\n",
    "        \"severity_id\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_priority\",\n",
    "        \"tag\",\n",
    "        \"transport\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Inventory\": {\n",
    "        \"array\",\n",
    "        \"blocksize\",\n",
    "        \"cluster\",\n",
    "        \"cpu_cores\",\n",
    "        \"cpu_count\",\n",
    "        \"cpu_mhz\",\n",
    "        \"description\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_ip\",\n",
    "        \"dest_priority\",\n",
    "        \"dns\",\n",
    "        \"enabled\",\n",
    "        \"family\",\n",
    "        \"fd_max\",\n",
    "        \"hypervisor\",\n",
    "        \"hypervisor_id\",\n",
    "        \"inline_nat\",\n",
    "        \"interactive\",\n",
    "        \"interface\",\n",
    "        \"ip\",\n",
    "        \"latency\",\n",
    "        \"lb_method\",\n",
    "        \"mac\",\n",
    "        \"mem\",\n",
    "        \"mount\",\n",
    "        \"name\",\n",
    "        \"node\",\n",
    "        \"node_port\",\n",
    "        \"os\",\n",
    "        \"parent\",\n",
    "        \"password\",\n",
    "        \"read_blocks\",\n",
    "        \"read_latency\",\n",
    "        \"read_ops\",\n",
    "        \"serial\",\n",
    "        \"shell\",\n",
    "        \"size\",\n",
    "        \"snapshot\",\n",
    "        \"src_ip\",\n",
    "        \"status\",\n",
    "        \"storage\",\n",
    "        \"tag\",\n",
    "        \"time\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_id\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\",\n",
    "        \"version\",\n",
    "        \"vip_port\",\n",
    "        \"write_blocks\",\n",
    "        \"write_latency\",\n",
    "        \"write_ops\"\n",
    "    },\n",
    "    \"Java Virtual Machines (JVM)\": {\n",
    "        \"cm_enabled\",\n",
    "        \"cm_supported\",\n",
    "        \"committed_memory\",\n",
    "        \"compilation_time\",\n",
    "        \"cpu_time\",\n",
    "        \"cpu_time_enabled\",\n",
    "        \"cpu_time_supported\",\n",
    "        \"current_cpu_time\",\n",
    "        \"current_loaded\",\n",
    "        \"current_user_time\",\n",
    "        \"daemon_thread_count\",\n",
    "        \"free_physical_memory\",\n",
    "        \"free_swap\",\n",
    "        \"heap_committed\",\n",
    "        \"heap_initial\",\n",
    "        \"heap_max\",\n",
    "        \"heap_used\",\n",
    "        \"jvm_description\",\n",
    "        \"max_file_descriptors\",\n",
    "        \"non_heap_committed\",\n",
    "        \"non_heap_initial\",\n",
    "        \"non_heap_max\",\n",
    "        \"non_heap_used\",\n",
    "        \"objects_pending\",\n",
    "        \"omu_supported\",\n",
    "        \"open_file_descriptors\",\n",
    "        \"os\",\n",
    "        \"os_architecture\",\n",
    "        \"os_version\",\n",
    "        \"peak_thread_count\",\n",
    "        \"physical_memory\",\n",
    "        \"process_name\",\n",
    "        \"start_time\",\n",
    "        \"swap_space\",\n",
    "        \"synch_supported\",\n",
    "        \"system_load\",\n",
    "        \"tag\",\n",
    "        \"thread_count\",\n",
    "        \"threads_started\",\n",
    "        \"total_loaded\",\n",
    "        \"total_processors\",\n",
    "        \"total_unloaded\",\n",
    "        \"uptime\",\n",
    "        \"vendor_product\",\n",
    "        \"version\"\n",
    "    },\n",
    "    \"Malware\": {\n",
    "        \"action\",\n",
    "        \"category\",\n",
    "        \"date\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_nt_domain\",\n",
    "        \"dest_priority\",\n",
    "        \"dest_requires_av\",\n",
    "        \"file_hash\",\n",
    "        \"file_name\",\n",
    "        \"file_path\",\n",
    "        \"product_version\",\n",
    "        \"sender\",\n",
    "        \"severity_id\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"signature_version\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_priority\",\n",
    "        \"tag\",\n",
    "        \"url\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Network Resolution (DNS)\": {\n",
    "        \"additional_answer_count\",\n",
    "        \"answer\",\n",
    "        \"answer_count\",\n",
    "        \"authority_answer_count\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_port\",\n",
    "        \"dest_priority\",\n",
    "        \"duration\",\n",
    "        \"message_type\",\n",
    "        \"name\",\n",
    "        \"query\",\n",
    "        \"query_count\",\n",
    "        \"query_type\",\n",
    "        \"record_type\",\n",
    "        \"reply_code\",\n",
    "        \"reply_code_id\",\n",
    "        \"response_time\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_port\",\n",
    "        \"src_priority\",\n",
    "        \"tag\",\n",
    "        \"transaction_id\",\n",
    "        \"transport\",\n",
    "        \"ttl\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Network Sessions\": {\n",
    "        \"action\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_dns\",\n",
    "        \"dest_ip\",\n",
    "        \"dest_mac\",\n",
    "        \"dest_nt_host\",\n",
    "        \"dest_priority\",\n",
    "        \"duration\",\n",
    "        \"lease_duration\",\n",
    "        \"lease_scope\",\n",
    "        \"response_time\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_dns\",\n",
    "        \"src_ip\",\n",
    "        \"src_mac\",\n",
    "        \"src_nt_host\",\n",
    "        \"src_priority\",\n",
    "        \"tag\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Network Traffic\": {\n",
    "        \"action\",\n",
    "        \"app\",\n",
    "        \"bytes\",\n",
    "        \"bytes_in\",\n",
    "        \"bytes_out\",\n",
    "        \"channel\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_interface\",\n",
    "        \"dest_ip\",\n",
    "        \"dest_mac\",\n",
    "        \"dest_port\",\n",
    "        \"dest_priority\",\n",
    "        \"dest_translated_ip\",\n",
    "        \"dest_translated_port\",\n",
    "        \"dest_zone\",\n",
    "        \"direction\",\n",
    "        \"duration\",\n",
    "        \"dvc\",\n",
    "        \"dvc_bunit\",\n",
    "        \"dvc_category\",\n",
    "        \"dvc_ip\",\n",
    "        \"dvc_mac\",\n",
    "        \"dvc_priority\",\n",
    "        \"dvc_zone\",\n",
    "        \"flow_id\",\n",
    "        \"icmp_code\",\n",
    "        \"icmp_type\",\n",
    "        \"packets\",\n",
    "        \"packets_in\",\n",
    "        \"packets_out\",\n",
    "        \"process_id\",\n",
    "        \"protocol\",\n",
    "        \"protocol_version\",\n",
    "        \"response_time\",\n",
    "        \"rule\",\n",
    "        \"session_id\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_interface\",\n",
    "        \"src_ip\",\n",
    "        \"src_mac\",\n",
    "        \"src_port\",\n",
    "        \"src_priority\",\n",
    "        \"src_translated_ip\",\n",
    "        \"src_translated_port\",\n",
    "        \"src_zone\",\n",
    "        \"ssid\",\n",
    "        \"tag\",\n",
    "        \"tcp_flag\",\n",
    "        \"tos\",\n",
    "        \"transport\",\n",
    "        \"ttl\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_account\",\n",
    "        \"vendor_product\",\n",
    "        \"vlan\",\n",
    "        \"wifi\"\n",
    "    },\n",
    "    \"Performance\": {\n",
    "        \"action\",\n",
    "        \"array\",\n",
    "        \"blocksize\",\n",
    "        \"cluster\",\n",
    "        \"cpu_load_mhz\",\n",
    "        \"cpu_load_percent\",\n",
    "        \"cpu_time\",\n",
    "        \"cpu_user_percent\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"dest_should_timesync\",\n",
    "        \"dest_should_update\",\n",
    "        \"fan_speed\",\n",
    "        \"fd_max\",\n",
    "        \"fd_used\",\n",
    "        \"hypervisor_id\",\n",
    "        \"latency\",\n",
    "        \"mem\",\n",
    "        \"mem_committed\",\n",
    "        \"mem_free\",\n",
    "        \"mem_used\",\n",
    "        \"mount\",\n",
    "        \"parent\",\n",
    "        \"power\",\n",
    "        \"read_blocks\",\n",
    "        \"read_latency\",\n",
    "        \"read_ops\",\n",
    "        \"resource_type\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"storage\",\n",
    "        \"storage_free\",\n",
    "        \"storage_free_percent\",\n",
    "        \"storage_used\",\n",
    "        \"storage_used_percent\",\n",
    "        \"swap\",\n",
    "        \"swap_free\",\n",
    "        \"swap_used\",\n",
    "        \"tag\",\n",
    "        \"temperature\",\n",
    "        \"thruput\",\n",
    "        \"thruput_max\",\n",
    "        \"uptime\",\n",
    "        \"write_blocks\",\n",
    "        \"write_latency\",\n",
    "        \"write_ops\"\n",
    "    },\n",
    "    \"Splunk Audit Logs\": {\n",
    "        \"access_count\",\n",
    "        \"access_time\",\n",
    "        \"action_mode\",\n",
    "        \"action_name\",\n",
    "        \"action_status\",\n",
    "        \"app\",\n",
    "        \"buckets\",\n",
    "        \"buckets_size\",\n",
    "        \"complete\",\n",
    "        \"component\",\n",
    "        \"cron\",\n",
    "        \"datamodel\",\n",
    "        \"digest\",\n",
    "        \"duration\",\n",
    "        \"earliest\",\n",
    "        \"event_id\",\n",
    "        \"host\",\n",
    "        \"info\",\n",
    "        \"is_inprogress\",\n",
    "        \"last_error\",\n",
    "        \"last_sid\",\n",
    "        \"latest\",\n",
    "        \"mod_time\",\n",
    "        \"orig_rid\",\n",
    "        \"orig_sid\",\n",
    "        \"retention\",\n",
    "        \"rid\",\n",
    "        \"savedsearch_name\",\n",
    "        \"search\",\n",
    "        \"search_et\",\n",
    "        \"search_lt\",\n",
    "        \"search_name\",\n",
    "        \"search_type\",\n",
    "        \"sid\",\n",
    "        \"signature\",\n",
    "        \"size\",\n",
    "        \"source\",\n",
    "        \"sourcetype\",\n",
    "        \"spent\",\n",
    "        \"splunk_server\",\n",
    "        \"status\",\n",
    "        \"summary_id\",\n",
    "        \"uri\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"view\"\n",
    "    },\n",
    "    \"TicketManagement\": {\n",
    "        \"affect_dest\",\n",
    "        \"change\",\n",
    "        \"comments\",\n",
    "        \"description\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"incident\",\n",
    "        \"priority\",\n",
    "        \"problem\",\n",
    "        \"severity\",\n",
    "        \"severity_id\",\n",
    "        \"splunk_id\",\n",
    "        \"splunk_realm\",\n",
    "        \"src_user\",\n",
    "        \"src_user_bunit\",\n",
    "        \"src_user_category\",\n",
    "        \"src_user_priority\",\n",
    "        \"status\",\n",
    "        \"tag\",\n",
    "        \"ticket_id\",\n",
    "        \"time_submitted\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\"\n",
    "    },\n",
    "    \"Updates\": {\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"dest_should_update\",\n",
    "        \"dvc\",\n",
    "        \"file_hash\",\n",
    "        \"file_name\",\n",
    "        \"severity\",\n",
    "        \"severity_id\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"status\",\n",
    "        \"tag\",\n",
    "        \"vendor_product\"\n",
    "    },\n",
    "    \"Vulnerabilities\": {\n",
    "        \"bugtraq\",\n",
    "        \"category\",\n",
    "        \"cert\",\n",
    "        \"cve\",\n",
    "        \"cvss\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_priority\",\n",
    "        \"dvc\",\n",
    "        \"dvc_bunit\",\n",
    "        \"dvc_category\",\n",
    "        \"dvc_priority\",\n",
    "        \"msft\",\n",
    "        \"mskb\",\n",
    "        \"severity\",\n",
    "        \"severity_id\",\n",
    "        \"signature\",\n",
    "        \"signature_id\",\n",
    "        \"tag\",\n",
    "        \"url\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\",\n",
    "        \"xref\"\n",
    "    },\n",
    "    \"Web\": {\n",
    "        \"action\",\n",
    "        \"app\",\n",
    "        \"bytes\",\n",
    "        \"bytes_in\",\n",
    "        \"bytes_out\",\n",
    "        \"cached\",\n",
    "        \"category\",\n",
    "        \"cookie\",\n",
    "        \"dest\",\n",
    "        \"dest_bunit\",\n",
    "        \"dest_category\",\n",
    "        \"dest_port\",\n",
    "        \"dest_priority\",\n",
    "        \"duration\",\n",
    "        \"error_code\",\n",
    "        \"http_content_type\",\n",
    "        \"http_method\",\n",
    "        \"http_referrer\",\n",
    "        \"http_referrer_domain\",\n",
    "        \"http_user_agent\",\n",
    "        \"http_user_agent_length\",\n",
    "        \"operation\",\n",
    "        \"response_time\",\n",
    "        \"site\",\n",
    "        \"src\",\n",
    "        \"src_bunit\",\n",
    "        \"src_category\",\n",
    "        \"src_priority\",\n",
    "        \"status\",\n",
    "        \"storage_name\",\n",
    "        \"tag\",\n",
    "        \"uri_path\",\n",
    "        \"uri_query\",\n",
    "        \"url\",\n",
    "        \"url_domain\",\n",
    "        \"url_length\",\n",
    "        \"user\",\n",
    "        \"user_bunit\",\n",
    "        \"user_category\",\n",
    "        \"user_priority\",\n",
    "        \"vendor_product\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87a48315-8822-4696-bb1f-f108492344dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Helpers to download relevant docs\n",
    "\n",
    "The provided Python code automates the downloading and local storage of various security and logging documentation. It first ensures that the target directories exist and then defines a reusable `download_file()` to fetch files from a URL and save them locally. \n",
    "\n",
    "Specific functions are defined to download different sets of documents: `download_splunk_cim_json()` retrieves multiple Splunk CIM JSON files from a GitHub repository, `download_zeek_protocol_docs()` downloads a Zeek protocol PDF, `download_sysmon_docs()` fetches a Sysmon cheatsheet PDF, and `download_osquery_schema()` downloads the osquery schema JSON file. \n",
    "\n",
    "Finally, the `download_all_docs()` orchestrates these calls to ensure all relevant documentation is downloaded and organized into their respective directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41f2c9b4-4ad2-475f-bca0-1069ac7d552c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Directory to store downloaded documents\n",
    "os.makedirs(VECTOR_DOCS_DIR, exist_ok=True)\n",
    "\n",
    "def download_file(url, local_path):\n",
    "    \"\"\"Download a file from a URL and save it locally.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(local_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {local_path}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "\n",
    "def download_splunk_cim_json():\n",
    "    \"\"\"Download all Splunk CIM JSON files.\"\"\"\n",
    "    base_url = \"https://raw.githubusercontent.com/splunk/addonfactory-splunk_sa_cim/master/default/data/models/\"\n",
    "    files = [\n",
    "        \"Alerts.json\",\n",
    "        \"Application_State.json\",\n",
    "        \"Authentication.json\",\n",
    "        \"Certificates.json\",\n",
    "        \"Change.json\",\n",
    "        \"Change_Analysis.json\",\n",
    "        \"Compute_Inventory.json\",\n",
    "        \"DLP.json\",\n",
    "        \"Data_Access.json\",\n",
    "        \"Databases.json\",\n",
    "        \"Email.json\",\n",
    "        \"Endpoint.json\",\n",
    "        \"Event_Signatures.json\",\n",
    "        \"Interprocess_Messaging.json\",\n",
    "        \"Intrusion_Detection.json\",\n",
    "        \"JVM.json\",\n",
    "        \"Malware.json\",\n",
    "        \"Network_Resolution.json\",\n",
    "        \"Network_Sessions.json\",\n",
    "        \"Network_Traffic.json\",\n",
    "        \"Performance.json\",\n",
    "        \"Splunk_Audit.json\",\n",
    "        \"Splunk_CIM_Validation.json\",\n",
    "        \"Ticket_Management.json\",\n",
    "        \"Updates.json\",\n",
    "        \"Vulnerabilities.json\",\n",
    "        \"Web.json\",\n",
    "    ]\n",
    "    for file in list(MODEL_HINTS.keys()):\n",
    "        url = base_url + file\n",
    "        local_path = os.path.join(CIM_DOCS_DIR, file)\n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "        download_file(url, local_path)\n",
    "\n",
    "def download_zeek_protocol_docs():\n",
    "    \"\"\"Download Zeek protocol documentation.\"\"\"\n",
    "    urls = [\n",
    "        \"https://f.hubspotusercontent00.net/hubfs/8645105/Corelight_May2021/Pdf/002_CORELIGHT_080420_ZEEK_LOGS_US_ONLINE.pdf\"\n",
    "    ]\n",
    "    for url in urls:\n",
    "        local_path = os.path.join(SYSMON_DOCS_DIR, os.path.basename(url))\n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "        download_file(url, local_path)\n",
    "\n",
    "\n",
    "def download_sysmon_docs():\n",
    "    \"\"\"Download Sysmon documentation.\"\"\"\n",
    "    urls = [\n",
    "        \"https://networkforensic.dk/Sysmon/Files/Sysmon-Cheatsheet.pdf\"\n",
    "    ]\n",
    "    for url in urls:\n",
    "        local_path = os.path.join(SYSMON_DOCS_DIR, os.path.basename(url))\n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "        download_file(url, local_path)\n",
    "\n",
    "def download_osquery_schema():\n",
    "    \"\"\"Download osquery schema documentation.\"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/jmpsec/osctrl/refs/heads/main/deploy/osquery/data/5.14.1.json\"\n",
    "    local_path = os.path.join(OSQUERY_DOCS_DIR, \"5.14.1.json\")\n",
    "    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "    download_file(url, local_path)\n",
    "\n",
    "def download_all_docs():\n",
    "    \n",
    "    \"\"\"Download all necessary documentation.\"\"\"\n",
    "    download_splunk_cim_json()\n",
    "    download_zeek_protocol_docs()\n",
    "    download_sysmon_docs()\n",
    "    download_osquery_schema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52872ff0-586c-4783-9bdc-7833c4438141",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Vector DB bootstrap\n",
    "\n",
    "This Python function, `build_cim_index`, constructs or loads a persistent vector index for CIM documentation using ChromaDB. It first ensures the Chroma persistence directory exists and initializes a Chroma client and collection, wrapping it in a `ChromaVectorStore` and `StorageContext`. \n",
    "\n",
    "If an existing index is found in the collection, it reuses it; otherwise, it traverses the specified `vector_docs_dir`, loading all files with `SimpleDirectoryReader()`, tagging each document with its data model based on its folder, and collecting them. \n",
    "\n",
    "The documents are then split into nodes using `NODE_PARSER` and inserted into a new `VectorStoreIndex`, which is persisted in the Chroma directory. The function returns the vector index, either reused or newly built, while logging progress throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a74926fc-bffc-4a7a-853a-413e6cefbf58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_cim_index(vector_docs_dir: str = VECTOR_DOCS_DIR, chroma_dir: str = CHROMA_DIR) -> VectorStoreIndex:\n",
    "    # Ensure Chroma persistence directory exists\n",
    "    os.makedirs(chroma_dir, exist_ok=True)\n",
    "\n",
    "    client = chromadb.PersistentClient(path=chroma_dir)\n",
    "    collection = client.get_or_create_collection(CATALOG)\n",
    "    vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "    storage_ctx = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "    # ---- Check if index already exists ----\n",
    "    if collection.count() > 0:\n",
    "        print(f\"[INFO] Found existing index in {chroma_dir}, reusing Chroma collection...\")\n",
    "        return VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_ctx)\n",
    "\n",
    "    # ---- Otherwise build index ----\n",
    "    if not os.path.isdir(vector_docs_dir):\n",
    "        raise FileNotFoundError(f\"CIM docs folder not found: {vector_docs_dir}\")\n",
    "\n",
    "    docs = []\n",
    "    for root, _, files in os.walk(vector_docs_dir):\n",
    "        for f in files:\n",
    "            full = os.path.join(root, f)\n",
    "            print(f\"[LOAD] {full}\")\n",
    "            data_model = os.path.basename(root).replace(\" \", \"_\")\n",
    "            reader = SimpleDirectoryReader(input_files=[full])\n",
    "            loaded = reader.load_data()\n",
    "            for d in loaded:\n",
    "                d.metadata = d.metadata or {}\n",
    "                d.metadata.update({\"data_model\": data_model})\n",
    "            docs.extend(loaded)\n",
    "\n",
    "    # Parse and insert into index\n",
    "    nodes = NODE_PARSER.get_nodes_from_documents(docs)\n",
    "    index = VectorStoreIndex.from_documents([], storage_context=storage_ctx)\n",
    "    index.insert_nodes(nodes)\n",
    "\n",
    "    print(f\"[INFO] Built and stored new index at {chroma_dir}\")\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98284fec-2a2e-4218-833c-05d02dcd956b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Determine CIM model selection/mapping\n",
    "\n",
    "This code defines a set of functions for mapping a Databricks table to a Splunk CIM (Common Information Model) data model and generating a corresponding CTAS (Create Table As Select) SQL statement. The `choose_cim_model()` selects the best-fitting CIM data model for a table by scoring column names against predefined hints, retrieving relevant context from a vector index, and using an LLM to pick the most appropriate model, falling back to the heuristic if necessary. \n",
    "\n",
    "The `map_columns_to_cim()` uses the LLM with contextual CIM documentation to map each table column to a corresponding CIM field, producing a JSON array of source-to-CIM mappings and defaulting unmapped columns to themselves. \n",
    "\n",
    "Finally, `generate_ctas_sql()` constructs a SQL statement to create a target schema and table in Databricks with columns renamed according to the generated mappings, effectively transforming the source table to conform to the chosen CIM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b689633f-390a-403e-9242-ca85c66e333d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def choose_cim_model(table_name: str, columns: List[Dict], index: VectorStoreIndex) -> str:\n",
    "    col_names = [c[\"name\"] for c in columns]\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    for model, hints in MODEL_HINTS.items():\n",
    "        score = sum(1 for c in col_names for h in hints if h.lower() in c.lower())\n",
    "        if score > best_score:\n",
    "            best_score, best_model = score, model\n",
    "\n",
    "    retriever = index.as_retriever(similarity_top_k=4)\n",
    "    context = retriever.retrieve(\n",
    "        f\"Which Splunk CIM data model best fits a table named {table_name} with columns: {col_names}?\"\n",
    "    )\n",
    "    #context_text = \"\\n\\n\".join([n.node.get_text(MetadataMode.LLM) for n in context])\n",
    "    context_text = \"\\n\\n\".join([n.node.get_text() for n in context])\n",
    "\n",
    "    \n",
    "    candidate_list = \", \".join(CIM_DATA_MODELS)\n",
    "    prompt = f\"\"\"\n",
    "    You are a Splunk CIM expert.\n",
    "    Pick the single best matching Splunk CIM Data Model from this list:\n",
    "    {candidate_list}\n",
    "\n",
    "    Table: {table_name}\n",
    "    Columns: {col_names}\n",
    "\n",
    "    Context:\\n{context_text}\n",
    "\n",
    "    Answer with only the exact Data Model name from the list.\n",
    "    \"\"\"\n",
    "    resp = Settings.llm.complete(prompt)\n",
    "    picked = resp.text.strip()\n",
    "    if picked not in CIM_DATA_MODELS and best_model:\n",
    "        picked = best_model\n",
    "    return picked\n",
    "\n",
    "def map_columns_to_cim(model: str, table_name: str, columns: List[Dict], index: VectorStoreIndex) -> List[Tuple[str, str]]:\n",
    "    retriever = index.as_retriever(similarity_top_k=6)\n",
    "\n",
    "    \n",
    "    context = retriever.retrieve(\n",
    "        f\"Splunk CIM {model} model field reference and examples\"\n",
    "    )\n",
    "    context_text = \"\\n\\n\".join([n.node.get_text() for n in context])\n",
    "\n",
    "    \n",
    "    col_names = [c[\"name\"] for c in columns]\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are mapping a Databricks table's columns to Splunk CIM fields for the **{model}** data model.\n",
    "    Return ONLY valid JSON without markdown, without ```json``` tags.\n",
    "\n",
    "    Table: {table_name}\n",
    "    Columns: {col_names}\n",
    "\n",
    "    Use ts for all log event timestamps, hostname for all host identifies, computer names, etc\n",
    "\n",
    "    Using the context excerpts from CIM docs, produce a JSON array of objects with keys: source_col, cim_field.\n",
    "    If no close match, set cim_field = source_col.\n",
    "\n",
    "    Context:\\n{context_text}\n",
    "\n",
    "    Return ONLY valid JSON.\n",
    "    \"\"\"\n",
    "    resp = Settings.llm.complete(prompt)\n",
    "\n",
    "    try:\n",
    "        pairs = json.loads(resp.text)\n",
    "        out = []\n",
    "        for p in pairs:\n",
    "            sc = p.get(\"source_col\"); cf = p.get(\"cim_field\")\n",
    "            if sc and cf:\n",
    "                out.append((sc, cf))\n",
    "        mapped_src = {sc for sc, _ in out}\n",
    "        for c in col_names:\n",
    "            if c not in mapped_src:\n",
    "                out.append((c, c))\n",
    "\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        return [(c, c) for c in col_names]\n",
    "\n",
    "\n",
    "def generate_ctas_sql(catalog: str, source_schema: str, target_schema: str, table: str, mappings: List[Tuple[str, str]]) -> str:\n",
    "    select_list = \",\\n        \".join([f\"`{src}` AS `{dst}`\" for src, dst in mappings])\n",
    "    return f\"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS {catalog}.{target_schema};\n",
    "CREATE TABLE IF NOT EXISTS {catalog}.{target_schema}.`{table}` AS\n",
    "SELECT\n",
    "        {select_list}\n",
    "FROM {catalog}.{source_schema}.`{table}`;\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a726c7dd-9e0b-41c6-8b1f-d983645933f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Main flow\n",
    "\n",
    "This main function orchestrates an end-to-end workflow for mapping Databricks tables to Splunk CIM data models and optionally executing the resulting SQL. \n",
    "\n",
    "It first downloads all relevant documentation for Splunk CIM and related security tools, then builds a persistent vector index of these documents for semantic retrieval. Using SQLAlchemy, it inspects the source schema to get a list of tables and their columns. For each table, it determines the best-fitting CIM model using the vector index, maps table columns to corresponding CIM fields, and generates a CTAS SQL statement to transform the table into the target schema. \n",
    "\n",
    "All generated SQL is printed, and if the environment variable EXECUTE_SQL is set to true, the code executes the statements against the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "805570a8-d861-4b5a-a0d2-30a609cda342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:37:20,873 - INFO - Received command c on object id p0\n2025-09-04 00:37:21,367 - WARNING - [WARN] Parameter '_user_agent_entry' is deprecated; use 'user_agent_entry' instead. This parameter will be removed in the upcoming releases.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found existing index in ./chroma_btv_dc30_index, reusing Chroma collection...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:37:21,493 - INFO - Received status code 200 for POST request\n2025-09-04 00:37:21,494 - INFO - HTTP Response with status code 200, message: OK\n2025-09-04 00:37:21,496 - INFO - Successfully opened session 01f08927-51a1-1013-9d53-e935becd1e6f\n2025-09-04 00:37:21,819 - INFO - Received status code 200 for POST request\n2025-09-04 00:37:21,820 - INFO - HTTP Response with status code 200, message: OK\n2025-09-04 00:37:21,863 - WARNING - Retrying (Retry(total=1, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68c1d0>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")': /batch/\n2025-09-04 00:37:21,866 - WARNING - Retrying (Retry(total=0, connect=0, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68c2f0>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")': /batch/\n2025-09-04 00:37:21,871 - INFO - Backing off send_request(...) for 0.2s (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68dac0>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")))\n2025-09-04 00:37:22,110 - WARNING - Retrying (Retry(total=1, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68d2b0>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")': /batch/\n2025-09-04 00:37:22,113 - WARNING - Retrying (Retry(total=0, connect=0, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68d790>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")': /batch/\n2025-09-04 00:37:22,117 - INFO - Backing off send_request(...) for 0.4s (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68d5e0>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")))\n2025-09-04 00:37:22,128 - INFO - Received status code 200 for POST request\n2025-09-04 00:37:22,129 - INFO - HTTP Response with status code 200, message: OK\n2025-09-04 00:37:22,285 - INFO - Received status code 200 for POST request\n2025-09-04 00:37:22,286 - INFO - HTTP Response with status code 200, message: OK\n2025-09-04 00:37:22,562 - WARNING - Retrying (Retry(total=1, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68d5b0>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")': /batch/\n2025-09-04 00:37:22,565 - WARNING - Retrying (Retry(total=0, connect=0, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68cfe0>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")': /batch/\n2025-09-04 00:37:22,568 - INFO - Backing off send_request(...) for 2.9s (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68cc20>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")))\n2025-09-04 00:37:22,569 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:23,054 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:23,393 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:25,453 - WARNING - Retrying (Retry(total=1, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf68c110>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")': /batch/\n2025-09-04 00:37:25,463 - WARNING - Retrying (Retry(total=0, connect=0, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1de8d24380>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")': /batch/\n2025-09-04 00:37:25,470 - ERROR - Giving up send_request(...) after 4 tries (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0xff1ddf7bc530>: Failed to resolve 'us.i.posthog.com' ([Errno -3] Temporary failure in name resolution)\")))\n2025-09-04 00:37:30,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:30,357 - INFO - Received status code 200 for POST request\n2025-09-04 00:37:30,358 - INFO - HTTP Response with status code 200, message: OK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n-- Table: hmail_app | CIM Model: Email\nCREATE SCHEMA IF NOT EXISTS btv_dc30.gold;\nCREATE TABLE IF NOT EXISTS btv_dc30.gold.`hmail_app` AS\nSELECT\n        `hostname` AS `host`,\n        `ts` AS `_time`,\n        `service` AS `service`,\n        `session_id` AS `internal_message_id`,\n        `client_ip` AS `src`,\n        `message` AS `message`\nFROM btv_dc30.silver.`hmail_app`;\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:37:30,524 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:30,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:30,993 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:32,502 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:32,648 - INFO - Received status code 200 for POST request\n2025-09-04 00:37:32,648 - INFO - HTTP Response with status code 200, message: OK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n-- Table: hmail_imapd | CIM Model: Email\nCREATE SCHEMA IF NOT EXISTS btv_dc30.gold;\nCREATE TABLE IF NOT EXISTS btv_dc30.gold.`hmail_imapd` AS\nSELECT\n        `hostname` AS `host`,\n        `ts` AS `_time`,\n        `service` AS `service`,\n        `session_id` AS `internal_message_id`,\n        `client_ip` AS `src`,\n        `message` AS `message`\nFROM btv_dc30.silver.`hmail_imapd`;\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:37:32,848 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:33,423 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:33,663 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:36,663 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:36,789 - INFO - Received status code 200 for POST request\n2025-09-04 00:37:36,789 - INFO - HTTP Response with status code 200, message: OK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n-- Table: hmail_smtp | CIM Model: Email\nCREATE SCHEMA IF NOT EXISTS btv_dc30.gold;\nCREATE TABLE IF NOT EXISTS btv_dc30.gold.`hmail_smtp` AS\nSELECT\n        `hostname` AS `host`,\n        `ts` AS `_time`,\n        `sender` AS `src_user`,\n        `recipient` AS `recipient`,\n        `client_ip` AS `src`,\n        `server_ip` AS `dest`,\n        `protocol` AS `protocol`,\n        `status_code` AS `status_code`,\n        `session_id` AS `internal_message_id`\nFROM btv_dc30.silver.`hmail_smtp`;\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:37:36,935 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:37,476 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:37,611 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:39,471 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:39,595 - INFO - Received status code 200 for POST request\n2025-09-04 00:37:39,595 - INFO - HTTP Response with status code 200, message: OK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n-- Table: hmail_smtpd | CIM Model: Email\nCREATE SCHEMA IF NOT EXISTS btv_dc30.gold;\nCREATE TABLE IF NOT EXISTS btv_dc30.gold.`hmail_smtpd` AS\nSELECT\n        `hostname` AS `host`,\n        `ts` AS `_time`,\n        `service` AS `service`,\n        `client_ip` AS `src`,\n        `message` AS `message`\nFROM btv_dc30.silver.`hmail_smtpd`;\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:37:40,266 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:42,063 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:42,322 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:43,374 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-09-04 00:37:43,510 - INFO - Received status code 200 for POST request\n2025-09-04 00:37:43,511 - INFO - HTTP Response with status code 200, message: OK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n-- Table: hmail_tcpip | CIM Model: Email\nCREATE SCHEMA IF NOT EXISTS btv_dc30.gold;\nCREATE TABLE IF NOT EXISTS btv_dc30.gold.`hmail_tcpip` AS\nSELECT\n        `hostname` AS `src`,\n        `ts` AS `_time`,\n        `service` AS `service`,\n        `message` AS `message`\nFROM btv_dc30.silver.`hmail_tcpip`;\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:37:43,692 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:465)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:743)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:84)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:84)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:84)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:84)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:721)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.handleDriverRequest$1(Chauffeur.scala:918)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.$anonfun$applyOrElse$3(Chauffeur.scala:944)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:943)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:998)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:793)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:789)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:784)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:988)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:908)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:548)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:513)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:914)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:914)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:877)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:859)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$26(ActivityContextFactory.scala:331)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:331)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:513)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:408)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:111)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:111)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:93)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:465)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:743)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:84)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:84)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:84)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:84)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:721)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.handleDriverRequest$1(Chauffeur.scala:918)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.$anonfun$applyOrElse$3(Chauffeur.scala:944)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:943)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:998)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:793)",
        "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:789)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:784)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:988)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:908)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:548)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:513)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:914)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:914)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:877)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:859)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$26(ActivityContextFactory.scala:331)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:331)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:513)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:408)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:111)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:111)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:93)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    # Step 1: Download documents for Splunk CIM and security tools\n",
    "    #download_all_docs()\n",
    "\n",
    "    # Step 2: Build vector index with Splunk CIM and security tool documents\n",
    "    index = build_cim_index(VECTOR_DOCS_DIR, CHROMA_DIR)\n",
    "    \n",
    "\n",
    "    # Step 3: Obtain a list of tables\n",
    "    engine = create_engine(SQLALCHEMY_URL)\n",
    "    inspector = inspect(engine)\n",
    "    tables = inspector.get_table_names(schema=SOURCE_SCHEMA)\n",
    "\n",
    "    all_outputs: Dict[str, str] = {}\n",
    "    for table in tables:\n",
    "        cols = inspector.get_columns(table, schema=SOURCE_SCHEMA)\n",
    "        model = choose_cim_model(table, cols, index)\n",
    "        mappings = map_columns_to_cim(model, table, cols, index)\n",
    "        sql = generate_ctas_sql(CATALOG, SOURCE_SCHEMA, TARGET_SCHEMA, table, mappings)\n",
    "        all_outputs[table] = sql\n",
    "        print(f\"\\n-- Table: {table} | CIM Model: {model}\\n{sql}\\n\")\n",
    "\n",
    "    # if os.getenv(\"EXECUTE_SQL\", \"false\").lower() in (\"1\", \"true\", \"yes\"): \n",
    "    #     with engine.begin() as conn:\n",
    "    #         for table, sql in all_outputs.items():\n",
    "    #             for stmt in [s.strip() for s in sql.split(\";\\n\") if s.strip()]:\n",
    "    #                 conn.execute(text(stmt))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "chatgpt-gold-tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
